************************************ LSTM
1. Without attention:
    Train:
    Epoch 1: loss=3.410878896713257, BLEU=0.2402646392583847
    Epoch 2: loss=2.442970037460327, BLEU=0.26632457971572876
    Epoch 3: loss=1.977178931236267, BLEU=0.28031298518180847
    Epoch 4: loss=1.6272562742233276, BLEU=0.2891900837421417
    Epoch 5: loss=1.3575340509414673, BLEU=0.2932021915912628

    Test:
    The average BLEU score over the test set was 0.32948675751686096

2. With single-headed attention:
    Train:
    Epoch 1: loss=3.1797540187835693, BLEU=0.27627867460250854
    Epoch 2: loss=2.1284286975860596, BLEU=0.3057810962200165
    Epoch 3: loss=1.6586030721664429, BLEU=0.3185303509235382
    Epoch 4: loss=1.3257116079330444, BLEU=0.32551079988479614
    Epoch 5: loss=1.083091139793396, BLEU=0.32556045055389404

    Test:
    The average BLEU score over the test set was 0.361995667219162

3. With multi-headed attention:
    Train:
    Epoch 1: loss=3.311176300048828, BLEU=0.2669709324836731
    Epoch 2: loss=2.258260488510132, BLEU=0.29922235012054443
    Epoch 3: loss=1.830489993095398, BLEU=0.3136630654335022
    Epoch 4: loss=1.5377196073532104, BLEU=0.3221944272518158
    Epoch 5: loss=1.3229268789291382, BLEU=0.3270064890384674

    Test:
    The average BLEU score over the test set was 0.37311699986457825




************************************ RNN
1. Without attention:
    Train:
    Epoch 1: loss=3.5214834213256836, BLEU=0.23074758052825928
    Epoch 2: loss=2.87235426902771, BLEU=0.23849910497665405
    Epoch 3: loss=2.64913272857666, BLEU=0.24576961994171143
    Epoch 4: loss=2.5199246406555176, BLEU=0.246475949883461
    Epoch 5: loss=2.4410018920898438, BLEU=0.2499508112668991

    Test:
    The average BLEU score over the test set was 0.29581934213638306

2. With single-headed attention:
    Train:
    Epoch 1: loss=3.2095789909362793, BLEU=0.2666693329811096
    Epoch 2: loss=2.3990890979766846, BLEU=0.2785535156726837
    Epoch 3: loss=2.1015026569366455, BLEU=0.2844487130641937
    Epoch 4: loss=1.9214930534362793, BLEU=0.28382840752601624
    Epoch 5: loss=1.8027671575546265, BLEU=0.2900879681110382

    Test:
    The average BLEU score over the test set was 0.3381935656070709

3. With multi-headed attention:
    Train:
    Epoch 1: loss=4.077580451965332, BLEU=0.22835248708724976
    Epoch 2: loss=2.7917165756225586, BLEU=0.2553972005844116
    Epoch 3: loss=2.499986171722412, BLEU=0.2559944689273834
    Epoch 4: loss=2.334564447402954, BLEU=0.2663378417491913
    Epoch 5: loss=2.227739095687866, BLEU=0.2676231563091278

    Test:
    The average BLEU score over the test set was 0.3220921754837036



************************************ GRU
1. Without attention:
    Train:
    Epoch 1: loss=2.771009922027588, BLEU=0.3017280697822571
    Epoch 2: loss=1.8244677782058716, BLEU=0.31309929490089417
    Epoch 3: loss=1.4336775541305542, BLEU=0.31637489795684814
    Epoch 4: loss=1.2278473377227783, BLEU=0.31567689776420593
    Epoch 5: loss=1.1121180057525635, BLEU=0.3121306002140045

    Test:
    The average BLEU score over the test set was 0.35367587208747864

2. With single-headed attention:
    Train:
    Epoch 1: loss=2.8685035705566406, BLEU=0.29475006461143494
    Epoch 2: loss=1.9521911144256592, BLEU=0.3051273822784424
    Epoch 3: loss=1.5657531023025513, BLEU=0.3128630816936493
    Epoch 4: loss=1.3436716794967651, BLEU=0.31544795632362366
    Epoch 5: loss=1.2092632055282593, BLEU=0.3134279251098633

    Test:
    The average BLEU score over the test set was 0.36157143115997314

3. With multi-headed attention:
    Train:
    Epoch 1: loss=4.405467510223389, BLEU=0.23860523104667664
    Epoch 2: loss=2.533280611038208, BLEU=0.27131757140159607
    Epoch 3: loss=2.06412935256958, BLEU=0.2839457392692566
    Epoch 4: loss=1.7752196788787842, BLEU=0.2929581105709076
    Epoch 5: loss=1.587206244468689, BLEU=0.2957667410373688


    Test:
    The average BLEU score over the test set was 0.3466337025165558


Findings:
With all cell types (lstm, rnn, gru) models with attentions perform better than without attention.
in lstm the bleu scores for test set are 0.32 without attention, 0.36 with single head attention and 0.37 with multi head attention.
This shows the improvements that multi head attention gives to the model.
In which the model is capable of jointly learn information from different representations and as a result it gives us a more powerful model.
It also performs better than single head because there is more opportunity for model to learn.

In all cases, during the training, the losses decrease while the bleu score increases.
The model performs slightly better with test dataset.
It's a different and small set of data and probably easier for model after the training is done.
It shows the model is trained well and works fine with a new set of data. And there's not much overfit on the train dataset.
another thing that comes to mind is that in abcs.py we use teacher forcing in case of training, which may cause exposure bias and affect the bleu scores this way. While this is not the case in test.

cell type lstm and gru show better result than rnn.
While training the model with rnn, I received "user warnings about beam search not finishing" more (not on every iteration though, and the results are still in acceptable range)
So I guess that architecture-wise, rnn is not able to captures the features in the model as well as other types.
This issue with rnn in expected due to it's short term memory and gradient vanishing problem. it's hard for rnn to keep information for long.
And this is the reason that lstm is invented to improve rnn.
It's also shown in the results of this assignment how lstm works better that rnn.
lstm and gru uses memory cells to preserve essential information with the help of gates in them.
Also between lstm and gru, It seems that lstm is better specially in multi head case.





Lastely, I used my own machine with GPU to train and test models.
I tried a few of them in cs.teach servers to make sure there is no issue there.
While I got nearly same results without any error, there were more warnings about beam search on those servers.
I guess that warning also depends on GPU. Other than this, everything else works fine.
